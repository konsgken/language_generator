{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\shakespeare_plays.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import corpora\n",
    "corpora.shakespeare_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "corpus = corpora.shakespeare_sonnets\n",
    "words, word2idx = preprocessing.get_words(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model specification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, LSTM, Reshape, TimeDistributed, Embedding\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "def get_model(num_timesteps, num_words, embedding_dim, hidden_dim, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=num_words, \n",
    "                        input_length=num_timesteps,\n",
    "                        batch_input_shape=[batch_size, num_timesteps],\n",
    "                        output_dim=embedding_dim))\n",
    "    model.add(LSTM(units=hidden_dim, \n",
    "                   batch_input_shape=[batch_size, num_timesteps, embedding_dim], \n",
    "                   return_sequences=True, \n",
    "                   stateful=True))\n",
    "    model.add(TimeDistributed(Dense(num_words), input_shape=(num_timesteps, hidden_dim)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "class ResetStates(Callback):\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(num_timesteps, hidden_dim, embedding_dim, batch_size, num_epochs, corpus, word2idx, model=None):\n",
    "    num_words = len(word2idx)\n",
    "    model = model if model else get_model(num_timesteps, num_words, embedding_dim, hidden_dim, batch_size)\n",
    "    examples = preprocessing.vectorized_example_stream(corpus, num_timesteps, batch_size, word2idx, word_level=True)\n",
    "    total_num_words = preprocessing.count_words(corpus)\n",
    "    total_num_words = total_num_words - total_num_words % (num_timesteps * batch_size)\n",
    "    samples_per_epoch = total_num_words//num_timesteps\n",
    "    model.fit_generator(examples, samples_per_epoch, num_epochs, callbacks=[ResetStates()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n",
      "D:\\software\\Anaconda3\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n",
      "D:\\software\\Anaconda3\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n",
      "D:\\software\\Anaconda3\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "total num symbols 26643\n",
      "864/864 [==============================] - 183s 212ms/step - loss: 0.8887 - acc: 0.8666\n"
     ]
    }
   ],
   "source": [
    "num_timesteps = 30\n",
    "hidden_dim = 128\n",
    "embedding_dim = 50\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "trained_model = train_model(num_timesteps, hidden_dim, embedding_dim, batch_size, \n",
    "                            num_epochs, corpus,word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wordlevel.%s.h5' % os.path.basename(corpus)\n",
    "trained_model.save_weights(model_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_text(model, seed_words, temperature, word2ix, idx2word, N):\n",
    "    model.reset_states()\n",
    "    # first we initialize the state of the LSTM using the seed_str\n",
    "    for seed_word in seed_words:\n",
    "        seed_word_idx = word2idx[seed_word]\n",
    "        x = np.zeros(shape=model.input_shape)\n",
    "        x[0, 0] = seed_word_idx\n",
    "        probs = model.predict(x, verbose=0)\n",
    "        \n",
    "    # now we start generating text\n",
    "    probs = probs[0,0,:]\n",
    "    next_word_idx = sample(probs, temperature)\n",
    "    generated_text_idx = [next_word_idx]\n",
    "    generated_text = [idx2word[next_word_idx]]\n",
    "    x = np.zeros(shape=model.input_shape)\n",
    "    for i in range(N - 1):\n",
    "        last_word_idx = generated_text_idx[-1]\n",
    "        x = np.zeros(shape=model.input_shape)\n",
    "        x[0, 0] = last_word_idx\n",
    "        probs = model.predict(x, verbose=0)\n",
    "        probs = probs[0,0,:]\n",
    "        next_word_idx = sample(probs, temperature)\n",
    "        generated_text_idx.append(next_word_idx)\n",
    "        generated_text.append(idx2word[next_word_idx])        \n",
    "    return generated_text\n",
    "    \n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n",
      "D:\\software\\Anaconda3\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:76: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  \"The file scan_perform.c is not available. This do\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9316112b6bd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrained_model_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrained_model_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgenerated_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_model_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-981e7ce7aa6c>\u001b[0m in \u001b[0;36mgenerate_text\u001b[1;34m(model, seed_words, temperature, word2ix, idx2word, N)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mgenerated_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0midx2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_word_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mlast_word_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerated_text_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "seed_str = '''To be or not to be'''\n",
    "seed_str = [w.lower() for w in word_tokenize(seed_str)]\n",
    "trained_model_test = get_model(1, len(word2idx), embedding_dim, hidden_dim, 1)\n",
    "trained_model_test.load_weights(model_name)\n",
    "generated_text = generate_text(trained_model_test, seed_str, 1.1, word2idx, words, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(seed_str + generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
