{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corpora\n",
    "corpora.shakespeare_plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "from __future__ import print_function\n",
    "corpus = corpora.shakespeare_sonnets\n",
    "chars, char2idx = preprocessing.get_chars(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, LSTM, Reshape, TimeDistributed\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "def get_model(num_timesteps, num_chars, hidden_dims, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(output_dim=hidden_dims, \n",
    "                   batch_input_shape=[batch_size, num_timesteps, num_chars], \n",
    "                   return_sequences=True, \n",
    "                   stateful=True))\n",
    "    model.add(LSTM(output_dim=hidden_dims, return_sequences=True, stateful=True))\n",
    "    model.add(TimeDistributed(Dense(num_chars), input_shape=(num_timesteps, hidden_dims)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class ResetStates(Callback):\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(num_timesteps, hidden_dims, batch_size, num_epochs, corpus, char2idx, model=None):\n",
    "    num_chars = len(char2idx)\n",
    "    model = model if model else get_model(num_timesteps, num_chars, hidden_dims, batch_size)\n",
    "    examples = preprocessing.vectorized_example_stream(corpus, num_timesteps, batch_size, char2idx, word_level=False)\n",
    "    total_num_chars = preprocessing.count_chars(corpus)\n",
    "    total_num_chars = total_num_chars - total_num_chars % (num_timesteps * batch_size)\n",
    "    samples_per_epoch = total_num_chars//num_timesteps\n",
    "    model.fit_generator(examples, samples_per_epoch, num_epochs, callbacks=[ResetStates()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 50\n",
    "hidden_dims = 128\n",
    "batch_size = 100\n",
    "num_epochs = 1\n",
    "trained_model = train_model(num_timesteps, hidden_dims, batch_size, \n",
    "                            num_epochs, corpus, char2idx, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'charlevel.%s.h5' % os.path.basename(corpus)\n",
    "trained_model.save_weights(model_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_text(model, seed_str, temperature, char2idx, idx2chars, N):\n",
    "    model.reset_states()\n",
    "    # first we initialize the state of the LSTM using the seed_str\n",
    "    for seed_char in seed_str:\n",
    "        seed_char_idx = char2idx[seed_char]\n",
    "        x = np.zeros(shape=model.input_shape)\n",
    "        x[0, 0, seed_char_idx] = 1\n",
    "        probs = model.predict(x, verbose=0)\n",
    "        \n",
    "    # now we start generating text\n",
    "    probs = probs[0,0,:]\n",
    "    next_char_idx = sample(probs, temperature)\n",
    "    generated_text_idx = [next_char_idx]\n",
    "    generated_text = [idx2chars[next_char_idx]]\n",
    "    x = np.zeros(shape=model.input_shape)\n",
    "    for i in xrange(N - 1):\n",
    "        last_char_idx = generated_text_idx[-1]\n",
    "        x = np.zeros(shape=model.input_shape)\n",
    "        x[0, 0, last_char_idx] = 1\n",
    "        probs = model.predict(x, verbose=0)\n",
    "        probs = probs[0,0,:]\n",
    "        next_char = sample(probs, temperature)\n",
    "        generated_text_idx.append(next_char)\n",
    "        generated_text.append(idx2chars[next_char])        \n",
    "    return generated_text\n",
    "    \n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_str = '''123'''\n",
    "model_name = 'charlevel.%s.h5' % os.path.basename(corpus)\n",
    "hidden_dims = 128\n",
    "trained_model_test = get_model(1, len(char2idx), hidden_dims, 1)\n",
    "trained_model_test.load_weights(model_name)\n",
    "generated_text = generate_text(trained_model_test, seed_str, 0.1, char2idx, chars, 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed_str + ''.join(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
